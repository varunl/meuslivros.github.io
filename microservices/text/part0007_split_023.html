<?xml version='1.0' encoding='utf-8'?>
<html xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Splitting the Monolith</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body data-type="book" class="calibre">
<section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 5. Splitting the Monolith">
<div class="preface" id="splitting-chapter">
<section data-type="sect1" data-pdf-bookmark="The Reporting Database"><div class="preface" id="idp10406064">
<h1 class="calibre7" id="calibre_pb_24">The Reporting Database</h1>

<p class="author"><a data-type="indexterm" data-primary="reporting databases" data-secondary="monolithic approach to" id="idp10407440" class="calibre3"></a><a data-type="indexterm" data-primary="monolithic systems" data-secondary="reporting databases in" id="idp10408416" class="calibre3"></a>Reporting typically needs to group together data from across multiple parts of our organization in order to generate useful output. For example, we might want to enrich the data from our general ledger with descriptions of what was sold, which we get from a catalog. Or we might want to look at the shopping behavior of specific, high-value customers, which could require information from their purchase history and their customer profile.</p>

<p class="author">In a standard, monolithic service architecture, all our data is stored in one big database. This means all the data is in one place, so reporting across all the information is actually pretty easy, as we can simply join across the data via SQL queries or the like. Typically we won’t run these reports on the main database for fear of the load generated by our queries impacting the performance of the main system, so often these reporting systems hang on a read replica as shown in <a data-type="xref" href="part0007_split_023.html#a59-reporting-slave" class="calibre3">Figure 5-12</a>.</p>

<figure class="calibre16"><div id="a59-reporting-slave" class="figure">
<img src="../images/00033.jpeg" alt="A standard read-replica setup to facilitate reporting" hisrc="assets/bdms_0512.png" class="calibre17"/>
<h6 class="calibre18"><span class="firstname">Figure 5-12. </span>Standard read replication</h6>
</div></figure>

<p class="author">With this approach we have one sizeable upside — that all the data is already in one place, so we can use fairly straightforward tools to query it. But there are also a couple of downsides with this approach. First, the schema of the database is now effectively a shared API between the running monolithic services and any reporting system. So a change in schema has to be carefully managed. In reality, this is another impediment that reduces the chances of anyone wanting to take on the task of making and coordinating such a change.</p>

<p class="author">Second, we have limited options as to how the database can be optimized for either use case — backing the live system or the reporting system. Some databases let us make optimizations on read replicas to enable faster, more efficient reporting; for example, MySQL would allow us to run a different backend that doesn’t have the overhead of managing transactions. However, we cannot structure the data differently to make reporting faster if that change in data structure has a bad impact on the running system. What often happens is that the schema either ends up being great for one use case and lousy for the other, or else becomes the lowest common denominator, great for neither purpose.</p>

<p class="author">Finally, the database options available to us have exploded recently. While standard relational databases expose SQL query interfaces that work with many reporting tools, they aren’t always the best option for storing data for our running services. What if our application data is better modeled as a graph, as in Neo4j? Or what if we’d rather use a document store like MongoDB? Likewise, what if we wanted to explore using a column-oriented database like Cassandra for our reporting system, which makes it much easier to scale for larger volumes? Being constrained in having to have one database for both purposes results in us often not being able to make these choices and explore new options.</p>

<p class="author">So it’s not perfect, but it works (mostly). Now if our information is stored in multiple different systems, what do we do? Is there a way for us to bring all the data together to run our reports? And could we also potentially find a way to eliminate some of the downsides associated with the standard reporting database model?</p>

<p class="author">It turns out we have a number of viable alternatives to this approach. Which solution makes the most sense to you will depend on a number of factors, but we’ll explore a few different options that I have seen in practice.</p>
</div></section>













</div></section></body></html>
