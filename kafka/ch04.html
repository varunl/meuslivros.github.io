<?xml version="1.0" encoding="utf-8" ?>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Chapter&#xA0;4.&#xA0;Kafka Design</title><link rel="stylesheet" href="epub.css" type="text/css"/><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/></head><body id="page"><div class="chapter" title="Chapter&#xA0;4.&#xA0;Kafka Design"><div class="titlepage"><div><div><h1 class="title"><a id="ch04"/>Chapter&#xA0;4.&#xA0;Kafka Design</h1></div></div></div><p>Before we start getting our hands dirty by coding Kafka producers and consumers, let's quickly discuss the internal design of Kafka.</p><p>In this chapter we shall be focusing on the following topics:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Kafka design fundamentals</li><li class="listitem" style="list-style-type: disc">Message compression in Kafka</li><li class="listitem" style="list-style-type: disc">Cluster mirroring in Kafka</li><li class="listitem" style="list-style-type: disc">Replication in Kafka</li></ul></div><p>Due to the overheads associated with JMS and its various implementations and limitations with the scaling architecture, LinkedIn<a id="id600" class="indexterm"/> (<a class="ulink" href="http://www.linkedin.com">www.linkedin.com</a>) decided to build Kafka to address their need for monitoring activity stream data and operational metrics such as CPU, I/O usage, and request timings.</p><p>While developing Kafka, the main focus was to provide the following:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">An API for producers and consumers to support custom implementation</li><li class="listitem" style="list-style-type: disc">Low overhead for network and storage with message persistence</li><li class="listitem" style="list-style-type: disc">High throughput supporting millions of messages</li><li class="listitem" style="list-style-type: disc">Distributed and highly scalable architecture</li></ul></div><div class="section" title="Kafka design fundamentals"><div class="titlepage"><div><div><h1 class="title"><a id="ch04lvl1sec18"/>Kafka design fundamentals</h1></div></div></div><p>In a very basic structure, a producer <a id="id610" class="indexterm"/>publishes messages to a Kafka topic, which <a id="id6200" class="indexterm"/>is created on a Kafka broker acting as a Kafka server. Consumers then subscribe to the Kafka topic to get the messages. This is described in the following diagram:</p><div class="mediaobject"><img src="graphics/7938OS_04_01.jpg" alt="Kafka design fundamentals"/></div><p>In the preceding<a id="id630" class="indexterm"/> diagram a single node &#x2013; single broker architecture is shown. This architecture considers that all three parties&#x2014;producers, Kafka broker, and consumers&#x2014;are running on <a id="id640" class="indexterm"/>different machines.</p><p>Here, each consumer is represented as a process and these processes are organized within groups called<a id="id650" class="indexterm"/> <span class="strong"><strong>consumer groups</strong></span>.</p><p>A message is consumed by a single process (consumer) within the consumer group, and if the requirement is such that a single message is to be consumed by multiple consumers, all these consumers need to be kept in different consumer groups.</p><p>By Kafka design, the message state of any consumed message is maintained within the message consumer, and the Kafka broker does not maintain a record of what is consumed by whom, which also means that poor designing of a custom consumer ends up in reading the same message multiple times.</p><p>Important <a id="id66" class="indexterm"/>Kafka<a id="id67" class="indexterm"/> design facts are as follows:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">The fundamental backbone of Kafka is message caching and storing it on the filesystem. In Kafka, data is immediately written to the OS kernel page. Caching and flushing of data to the disk is configurable.</li><li class="listitem" style="list-style-type: disc">Kafka provides longer retention of messages ever after consumption, allowing consumers to reconsume, if required.</li><li class="listitem" style="list-style-type: disc">Kafka uses a message set to group messages to allow lesser network overhead.</li><li class="listitem" style="list-style-type: disc">Unlike most of the messaging systems, where metadata of the consumed messages are kept at server level, in Kafka, the state of the consumed messages is maintained at consumer level. This also addresses issues such as:<div class="itemizedlist"><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc">Loosing messages due to failure</li><li class="listitem" style="list-style-type: disc">Multiple deliveries of the same message</li></ul></div><p>By default, consumers store the state in ZooKeeper, but Kafka also allows storing it within other storage systems used for <span class="strong"><strong>Online Transaction Processing</strong></span> (<span class="strong"><strong>OLTP</strong></span>)<a id="id68" class="indexterm"/> applications as well.</p></li><li class="listitem" style="list-style-type: disc">In Kafka, producers and consumers work on the traditional push-and-pull model, where producers push the message to a Kafka broker and consumers pull the message from the broker.</li><li class="listitem" style="list-style-type: disc">Kafka does not have any concept of a master and treats all the brokers as peers. This approach facilitates addition and removal of a Kafka broker at any point, as the metadata of brokers are maintained in ZooKeeper and shared with producers and consumers.</li><li class="listitem" style="list-style-type: disc">In Kafka 0.7.x, ZooKeeper-based <a id="id69" class="indexterm"/>load balancing allows producers to discover the <a id="id70" class="indexterm"/>broker dynamically. A producer maintains a pool of broker connections, and constantly updates it using ZooKeeper watcher callbacks. But in Kafka 0.8.x, load balancing is achieved through Kafka metadata API and ZooKeeper can only be used to identify the list of available brokers.</li><li class="listitem" style="list-style-type: disc">Producers also have an option to choose between asynchronous or synchronous mode for sending messages to a broker.</li></ul></div></div></div></body></html>
