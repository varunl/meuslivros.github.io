<?xml version='1.0' encoding='utf-8'?>
<html xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Testing</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body data-type="book" class="calibre">
<section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Testing">
<div class="preface" id="testing-chapter">
<section data-type="sect1" data-pdf-bookmark="Testing After Production">
<div class="preface" id="idp11269504">
<section data-type="sect2" data-pdf-bookmark="Mean Time to Repair Over Mean Time Between Failures?"><div class="preface" id="idp11296096">
<h2 class="calibre15" id="calibre_pb_26">Mean Time to Repair Over Mean Time Between Failures?</h2>

<p class="author"><a data-type="indexterm" data-primary="testing" data-secondary="MTTR over MTBF" id="idp11297504" class="calibre3"></a><a data-type="indexterm" data-primary="mean time between failures (MTBF)" id="idp11298480" class="calibre3"></a><a data-type="indexterm" data-primary="mean time to repair (MTTR)" id="idp11299120" class="calibre3"></a><a data-type="indexterm" data-primary="MTBF (mean time between failures)" id="idp11299808" class="calibre3"></a><a data-type="indexterm" data-primary="MTTR (mean time to repair)" id="idp11300496" class="calibre3"></a>So by looking at techniques like blue/green deployment or canary releasing, we find a way to test closer to (or even in) production, and we also build tools to help us manage a failure if it occurs. Using these approaches is a tacit acknowledgment that we cannot spot and catch all problems before we actually release our software.</p>

<p class="author">Sometimes expending the same effort into getting better at remediation of a release can be significantly more beneficial than adding more automated functional tests. In the web operations world, this is often referred to as the trade-off between optimizing for <em class="calibre4">mean time between failures (MTBF)</em> and <em class="calibre4">mean time to repair (MTTR)</em>.</p>

<p class="author">Techniques to reduce the time to recovery can be as simple as very fast rollbacks coupled with good monitoring (which we’ll discuss in <a data-type="xref" href="part0010_split_000.html#monitoring-chapter" class="calibre3">Chapter 8</a>), like blue/green deployments. If we can spot a problem in production early, and roll back early, we reduce the impact to our customers. We can also use techniques like blue/green deployment, where we deploy a new version of our software and test it in situ prior to directing our users to the new version.</p>

<p class="author">For different organizations, this trade-off between MTBF and MTTR will vary, and much of this lies with understanding the true impact of failure in a production environment. However, most organizations that I see spending time creating functional test suites often expend little to no effort at all on better monitoring or recovering from failure. So while they may reduce the number of defects that occur in the first place, they can’t eliminate all of them, and are unprepared for dealing with them if they pop up in production.</p>

<p class="author">Trade-offs other than MTBF and MTTR exist. For example, if you are trying to work out if anyone will actually use your software, it may make much more sense to get something out now, to prove the idea or the business model before building robust software. In an environment where this is the case, testing may be overkill, as the impact of not knowing if your idea works is much higher than having a defect in production. In these situations, it can be quite sensible to avoid testing prior to production altogether.</p>
</div></section>





</div></section>













</div></section></body></html>
