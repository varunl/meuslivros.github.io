<?xml version='1.0' encoding='utf-8'?>
<html xmlns:epub="http://www.idpf.org/2007/ops" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Microservices at Scale</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link href="../stylesheet.css" rel="stylesheet" type="text/css"/>
<link href="../page_styles.css" rel="stylesheet" type="text/css"/>
</head>
  <body data-type="book" class="calibre">
<section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 11. Microservices at Scale">
<div class="preface" id="at-scale-chapter">
<section data-type="sect1" data-pdf-bookmark="Caching">
<div class="preface" id="idp12149248">
<section data-type="sect2" data-pdf-bookmark="Caching for Writes"><div class="preface" id="idp12183600">
<h2 class="calibre15" id="calibre_pb_27">Caching for Writes</h2>

<p class="author"><a data-type="indexterm" data-primary="caching" data-secondary="for writes" id="idp12184800" class="calibre3"></a><a data-type="indexterm" data-primary="microservices at scale" data-secondary="caching for writes" id="idp12185776" class="calibre3"></a>Although youâ€™ll find yourself using caching for reads more often, there are some use cases where caching for writes make sense. For example, if you make use of a write-behind cache, you can write to a local cache, and at some later point the data will be flushed to a downstream source, probably the canonical source of data. This can be useful when you have bursts of writes, or when there is a good chance that the same data will be written multiple times. When used to buffer and potentially batch writes, write-behind caches can be a useful further performance optimization.</p>

<p class="author">With a write-behind cache, if the buffered writes are suitably persistent, even if the downstream service is unavailable we could queue up the writes and send them through when it is available again.</p>
</div></section>













</div></section>













</div></section></body></html>
